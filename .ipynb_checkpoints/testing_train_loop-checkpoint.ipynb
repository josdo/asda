{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:          15043         345       11972          10        2724       14422\r\n",
      "Swap:             0           0           0\r\n"
     ]
    }
   ],
   "source": [
    "!free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python evaluate_cityscapes.py \\\n",
    "#     --restore-from ./snapshots/1280x640_restore_ft_GN_batchsize9_512x256_pp_ms_me0_classbalance7_kl0_lr1_drop0.2_seg0.5_BN_80_255_0.8_Noaug/GTA5_25000.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!watch -n 0.5 nvidia-smi\n",
    "#!watch -n 0.5 free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Tensorboard is logging to ./log/baseline_run\n",
      "-------lr_G: 0.000200-------\n",
      "(1000, 1000)\n",
      "(1000, 1000)\n",
      "(1000, 1000)\n",
      "(1000, 1000)\n",
      "(1000, 1000)\n",
      "(1000, 1000)\n",
      "(1000, 1000)\n",
      "(1000, 1000)\n",
      "(1000, 1000)\n",
      "(1000, 1000)\n",
      "(1000, 1000)\n",
      "(1000, 1000)\n",
      "(1000, 1000)\n",
      "(1000, 1000)\n",
      "(1000, 1000)\n",
      "(1000, 1000)\n",
      "(1000, 1000)\n",
      "torch.Size([1, 1000, 1000])\n",
      "tensor([1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
      "original loss: 1.793794\n",
      "original loss: 1.236256\n",
      "Elapsed time in update: 19.732514\n",
      "Traceback (most recent call last):\n",
      "  File \"train_ms.py\", line 362, in <module>\n",
      "    main()\n",
      "  File \"train_ms.py\", line 303, in main\n",
      "    loss_seg1, loss_seg2, loss_adv_target1, loss_adv_target2, loss_me, loss_kl, pred1, pred2, pred_target1, pred_target2, val_loss = Trainer.gen_update(images, images_t, labels, labels_t, i_iter)\n",
      "  File \"/home/sleepearly/asda/trainer_ms.py\", line 249, in gen_update\n",
      "    scaled_loss.backward()\n",
      "  File \"/opt/conda/lib/python3.7/contextlib.py\", line 119, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/handle.py\", line 123, in scale_loss\n",
      "    optimizer._post_amp_backward(loss_scaler)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\", line 249, in post_backward_no_master_weights\n",
      "    post_backward_models_are_masters(scaler, params, stashed_grads)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\", line 128, in post_backward_models_are_masters\n",
      "    scale_override=grads_have_scale/out_scale)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/amp/scaler.py\", line 117, in unscale\n",
      "    1./scale)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/apex/multi_tensor_apply/multi_tensor_apply.py\", line 30, in __call__\n",
      "    *args)\n",
      "RuntimeError: CUDA error: no kernel image is available for execution on the device (multi_tensor_apply at csrc/multi_tensor_apply.cuh:111)\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x47 (0x7f10d545c627 in /opt/conda/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: void multi_tensor_apply<2, ScaleFunctor<float, float>, float>(int, int, at::Tensor const&, std::vector<std::vector<at::Tensor, std::allocator<at::Tensor> >, std::allocator<std::vector<at::Tensor, std::allocator<at::Tensor> > > > const&, ScaleFunctor<float, float>, float) + 0x13a2 (0x7f10b83c41e2 in /opt/conda/lib/python3.7/site-packages/amp_C.cpython-37m-x86_64-linux-gnu.so)\n",
      "frame #2: multi_tensor_scale_cuda(int, at::Tensor, std::vector<std::vector<at::Tensor, std::allocator<at::Tensor> >, std::allocator<std::vector<at::Tensor, std::allocator<at::Tensor> > > >, float) + 0x781 (0x7f10b83c2191 in /opt/conda/lib/python3.7/site-packages/amp_C.cpython-37m-x86_64-linux-gnu.so)\n",
      "frame #3: <unknown function> + 0x21bac (0x7f10b83b2bac in /opt/conda/lib/python3.7/site-packages/amp_C.cpython-37m-x86_64-linux-gnu.so)\n",
      "frame #4: <unknown function> + 0x1ba74 (0x7f10b83aca74 in /opt/conda/lib/python3.7/site-packages/amp_C.cpython-37m-x86_64-linux-gnu.so)\n",
      "<omitting python frames>\n",
      "frame #40: __libc_start_main + 0xf1 (0x7f112a26e2e1 in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python train_ms.py \\\n",
    "    --restore-from ./aerial_network_training/checkpoints/vary_dropout_2_reduce_variance/latest_lr0.00025_gam2_drop0.00.pth \\\n",
    "    --num-classes 6 \\\n",
    "    --data-list ./dataset/potsdam_list/train.txt \\\n",
    "    --data-dir ./data/potsdam \\\n",
    "    --data-list-target ./dataset/dstl_list/train.txt \\\n",
    "    --data-dir-target ./data/dstl \\\n",
    "    --snapshot-dir baseline_run \\\n",
    "    --droprate 0.1 --batch-size 1 --learning-rate 2e-4 --crop-size 1000,1000 \\\n",
    "    --lambda-seg 0.5  --lambda-adv-target1 0.0002 --lambda-adv-target2 0.001 \\\n",
    "    --lambda-me-target 0  --lambda-kl-target 0.1  \\\n",
    "    --norm-style gn  --class-balance  --only-hard-label 80 \\\n",
    "    --max-value 7  --gpu-ids 0  --often-balance  --use-se \\ # --fp16 \\\n",
    "    --num-workers 16 --is-training --save-pred-every 100\n",
    "# --verbose_model_loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
